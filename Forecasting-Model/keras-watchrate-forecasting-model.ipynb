{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have TensorFlow version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "\n",
    "# This code was tested with TensorFlow v1.9\n",
    "print(\"You have TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>watchrate</th>\n",
       "      <th>taxonomy_type</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>globalviewcount</th>\n",
       "      <th>videocount</th>\n",
       "      <th>avgduration</th>\n",
       "      <th>avgtotalsecondsperview</th>\n",
       "      <th>totalsecondsperview</th>\n",
       "      <th>sumtotalvideoviews</th>\n",
       "      <th>proscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>201.640005</td>\n",
       "      <td>Rekognition-Celebrities</td>\n",
       "      <td>Anastasia Rodionova</td>\n",
       "      <td>2.836800e+04</td>\n",
       "      <td>4</td>\n",
       "      <td>44.634000</td>\n",
       "      <td>90</td>\n",
       "      <td>360</td>\n",
       "      <td>72</td>\n",
       "      <td>yogurt - rfg yogurt - dannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>56.239810</td>\n",
       "      <td>Rekognition-Labels</td>\n",
       "      <td>Musical</td>\n",
       "      <td>6.241358e+07</td>\n",
       "      <td>162</td>\n",
       "      <td>403.628673</td>\n",
       "      <td>227</td>\n",
       "      <td>36835</td>\n",
       "      <td>7367</td>\n",
       "      <td>yogurt - rfg yogurt - dannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>63.194697</td>\n",
       "      <td>Rekognition-Labels</td>\n",
       "      <td>Rice</td>\n",
       "      <td>1.238469e+10</td>\n",
       "      <td>2557</td>\n",
       "      <td>58.549217</td>\n",
       "      <td>37</td>\n",
       "      <td>96460</td>\n",
       "      <td>19292</td>\n",
       "      <td>yogurt - rfg yogurt - dannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>56.115021</td>\n",
       "      <td>Rekognition-Celebrities</td>\n",
       "      <td>Suzana Ćebić</td>\n",
       "      <td>5.873362e+08</td>\n",
       "      <td>519</td>\n",
       "      <td>90.884756</td>\n",
       "      <td>51</td>\n",
       "      <td>26625</td>\n",
       "      <td>5325</td>\n",
       "      <td>yogurt - rfg yogurt - dannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53.433986</td>\n",
       "      <td>Rekognition-Labels</td>\n",
       "      <td>Word</td>\n",
       "      <td>1.158450e+12</td>\n",
       "      <td>26203</td>\n",
       "      <td>91.701937</td>\n",
       "      <td>49</td>\n",
       "      <td>1300015</td>\n",
       "      <td>260003</td>\n",
       "      <td>yogurt - rfg yogurt - dannon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       watchrate            taxonomy_type             tag_name  \\\n",
       "3111  201.640005  Rekognition-Celebrities  Anastasia Rodionova   \n",
       "1115   56.239810       Rekognition-Labels              Musical   \n",
       "234    63.194697       Rekognition-Labels                 Rice   \n",
       "703    56.115021  Rekognition-Celebrities         Suzana Ćebić   \n",
       "22     53.433986       Rekognition-Labels                 Word   \n",
       "\n",
       "      globalviewcount  videocount  avgduration  avgtotalsecondsperview  \\\n",
       "3111     2.836800e+04           4    44.634000                      90   \n",
       "1115     6.241358e+07         162   403.628673                     227   \n",
       "234      1.238469e+10        2557    58.549217                      37   \n",
       "703      5.873362e+08         519    90.884756                      51   \n",
       "22       1.158450e+12       26203    91.701937                      49   \n",
       "\n",
       "      totalsecondsperview  sumtotalvideoviews                      proscore  \n",
       "3111                  360                  72  yogurt - rfg yogurt - dannon  \n",
       "1115                36835                7367  yogurt - rfg yogurt - dannon  \n",
       "234                 96460               19292  yogurt - rfg yogurt - dannon  \n",
       "703                 26625                5325  yogurt - rfg yogurt - dannon  \n",
       "22                1300015              260003  yogurt - rfg yogurt - dannon  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv('dannon_james.csv')\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "# Print the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do some preprocessing\n",
    "data = data[pd.notnull(data['watchrate'])]\n",
    "data = data[pd.notnull(data['tag_name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3061\n",
      "Test size: 766\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_size = int(len(data) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train features\n",
    "tag_name_train = data['tag_name'][:train_size]\n",
    "taxonomy_type_train = data['taxonomy_type'][:train_size]\n",
    "\n",
    "# Train labels\n",
    "labels_train = data['watchrate'][:train_size]\n",
    "\n",
    "# Test features\n",
    "tag_name_test = data['tag_name'][train_size:]\n",
    "taxonomy_type_test = data['taxonomy_type'][train_size:]\n",
    "\n",
    "# Test labels\n",
    "labels_test = data['watchrate'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a tokenizer to preprocess our tag names\n",
    "vocab_size = 12000 # This is a hyperparameter, experiment with different values for the dataset\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size, char_level=False)\n",
    "tokenize.fit_on_texts(tag_name_train) # only fit on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wide model feature 1: sparse bag of words (bow) vocab_size vector \n",
    "tag_name_bow_train = tokenize.texts_to_matrix(tag_name_train)\n",
    "tag_name_bow_test = tokenize.texts_to_matrix(tag_name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wide feature 2: one-hot vector of taxonomy types\n",
    "\n",
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(taxonomy_type_train)\n",
    "taxonomy_type_train = encoder.transform(taxonomy_type_train)\n",
    "taxonomy_type_test = encoder.transform(taxonomy_type_test)\n",
    "num_classes = np.max(taxonomy_type_train) + 1\n",
    "\n",
    "# Convert labels to one hot\n",
    "taxonomy_type_train = keras.utils.to_categorical(taxonomy_type_train, num_classes)\n",
    "taxonomy_type_test = keras.utils.to_categorical(taxonomy_type_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our wide model with the functional API\n",
    "bow_inputs = layers.Input(shape=(vocab_size,))\n",
    "taxonomy_type_inputs = layers.Input(shape=(num_classes,))\n",
    "merged_layer = layers.concatenate([bow_inputs, taxonomy_type_inputs])\n",
    "merged_layer = layers.Dense(256, activation='relu')(merged_layer)\n",
    "predictions = layers.Dense(1)(merged_layer)\n",
    "wide_model = keras.Model(inputs=[bow_inputs, taxonomy_type_inputs], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 12010)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          3074816     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,075,073\n",
      "Trainable params: 3,075,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wide_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "print(wide_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep model feature: word embeddings of video tag names\n",
    "train_embed = tokenize.texts_to_sequences(tag_name_train)\n",
    "test_embed = tokenize.texts_to_sequences(tag_name_test)\n",
    "\n",
    "max_seq_length = 170\n",
    "train_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_embed, maxlen=max_seq_length, padding=\"post\")\n",
    "test_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_embed, maxlen=max_seq_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 170, 8)            96000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1360)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1361      \n",
      "=================================================================\n",
      "Total params: 97,361\n",
      "Trainable params: 97,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define our deep model with the Functional API\n",
    "deep_inputs = layers.Input(shape=(max_seq_length,))\n",
    "embedding = layers.Embedding(vocab_size, 8, input_length=max_seq_length)(deep_inputs)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "embed_out = layers.Dense(1)(embedding)\n",
    "deep_model = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.compile(loss='mse',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 170)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 12010)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 170, 8)       96000       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          3074816     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1360)         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1361        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            3           flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,172,437\n",
      "Trainable params: 3,172,437\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Combine wide and deep into one model\n",
    "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
    "merged_out = layers.Flatten()(merged_out)\n",
    "merged_out = layers.Dense(1)(merged_out)\n",
    "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
    "print(combined_model.summary())\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (12000,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-835675ddd987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcombined_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_name_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaxonomy_type_train\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_embed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (12000,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "combined_model.fit([tag_name_train, taxonomy_type_train] + [train_embed], labels_train, epochs=10, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
